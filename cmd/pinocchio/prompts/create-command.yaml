name: create-command
short: Generate a pinocchio query
factories:
  client:
    timeout: 120
  chat:
    engine: gpt-4
    temperature: 0.2
    max_response_tokens: 2048
    stop: []
    stream: true
flags:
  - name: additional_system
    type: stringList
    help: Additional system prompt
  - name: additional
    type: stringList
    help: Additional prompt
  - name: prompt
    type: stringFromFile
    help: Prompt for the command
    required: true
  - name: context
    type: fileList
    help: Additional context
  - name: types
    type: stringList
    help: List of types
    default:
      - int
      - file
      - fileList
      - string
      - stringList
      - stringFromFile
      - objectFromFile
      - objectListFromFile
      - stringListFromFile
      - intList
      - float
      - bool
      - floatList
      - choice
      - choiceList
  - name: example_name
    type: string
    help: Name of the example
    default: Generate animal descriptions
  - name: example
    type: stringFromFile
    help: Example of the command
    default: |
      name: animals
      short: Generate animal descriptions.
      factories:
        client:
          timeout: 120
        chat:
          engine: gpt-4
          temperature: 0.2
          max_response_tokens: 2048
          stop: []
          stream: true
      flags:
        - name: name
          type: string
          help: Animal name
          required: true
        - name: color
          type: string
          help: Animal color
        - name: species
          type: stringList
          help: Animal species
        - name: additional_system
          type: string
          help: Additional system prompt
          default: ""
        - name: additional
          type: string
          help: Additional prompt
          default: ""
        - name: context
          type: fileList
          help: Additional context from files
        - name: concise
          type: bool
          help: Give concise answers
          default: false
        - name: use_bullets
          type: bool
          help: Use bullet points in the answer
          default: false
        - name: use_keywords
          type: bool
          help: Use keywords in the answer
          default: false
      system-prompt: |
          You are an intrepid animalist. You know all species of animals. You write clearly and concisely.
          {{ .additional_system }}
      prompt: |
        Write a description of the animal {{ .name }}.
        {{ if .color }}It is of color {{ .color }}.{{end}}
        {{ if .species }}It is a {{ .species | join ", " }}.{{end}}
      
        The output format is a YAML file with the following structure:
      
        ```yaml
        name: ...
        color: ...
        species: ...
        description: ...
        ```
      
        {{ if .additional }}
        Additional instructions:
        {{ .additional }}
        {{ end }}
        
        {{ if .context}}Additional Context:
        {{ range .context }}
        Path: {{ .Path }}
        ---
        {{ .Content }}
        ---
        {{- end }}
        {{ end }}
        {{ if .concise -}}
        Give a concise answer, answer in a single sentence if possible, skip unnecessary explanations.
        {{- end }}
        {{ if .use_bullets -}}
        Use bullet points in the answer.
        {{- end }}
        {{ if .use_keywords -}}
        Use keywords in the answer, not full sentences.
        {{- end }}
system-prompt: |
  You are an experienced technology professional and technical leader in software.
  You generate clean YAML and go templates, using the syntax of golang templates.
  You are good at reasoning and prompting large language models.
  {{ .additional_system | join "\n" }}
prompt: |
  I want to generate command templates for prompting large language models, stored in YAML and with the `prompt` and `system-prompt` 
  field using go template syntax. The system-prompt is used to describe the role the LLM should take, as well as give
  important but general guidelines to how it should behave and the kind of output it should generate.
  
  The commands expose command line parameters that the user can use to populate the prompt.
  
  The `flags` stored in the YAML can be of different types: {{ .types | join ", " }}. These are then passed to the go 
  template.
  
  `FileData` is a structure that provides detailed information about a file.
  This is useful when your command needs to work with files.
  A file has the following attribute that can be used in a template.
  
    Content: File's string content.
    ParsedContent: Parsed version of the file's content (for json and yaml files).
    ParseError: Any error that occurred during parsing.
    RawContent: File content in byte format.
    StringContent: File content as a string.
    IsList: Indicates if the content represents a list.
    IsObject: Signifies if the content denotes an object.
    BaseName: File's base name.
    Extension: File's extension.
    FileType: File's type.
    Path: File's path.
  
  The `factories` section is used to configure the API call to the model. Copy it as is unless requested.
  
  Instead of "x > 10", the template language uses "gt x 10".
  
  Here is a (short) example that uses a LLM to do {{ .example_name }}. While this example has terse
  system prompt and prompt, real command will have exhaustive and detailed prompts.
  
  ```yaml
  {{ .example }}
  ```
  
  {{- .additional | join "\n" }}
  
  Create a command that executes the following prompt. The resulting command should split the given prompt
  into a system prompt (about the persona and the role of the LLM) and a prompt (about the task at hand).
  
  The entire original prompt should be present in the command, don't abbreviate.
  
  Locations to use as template flags are marked XXX or in template format
  already, using golang template curly brace syntax.
  
  Try to minimally modify the original prompt. Do not try to add additional flags besides the marked ones.
  
  --- BEGIN PROMPT
  {{ .prompt }}
  --- END PROMPT
  
  {{ if .context}}Additional Context:
  {{ range .context }}
  Path: {{ .Path }}
  ---
  {{ .Content }}
  ---
  {{- end }}
  {{ end }}
  


